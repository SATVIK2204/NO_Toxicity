{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import sys\r\n",
    "from pickle import dump,load\r\n",
    "from collections import Counter\r\n",
    "from torch.nn.utils.rnn import pad_sequence\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "\r\n",
    "import torch \r\n",
    "\r\n",
    "\r\n",
    "sys.path.append('../../')\r\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../data/modified/data_to_work_on.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Explanation\\nWhy the edits made under my usern...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>You, sir, are my hero. Any chance you remember...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>159566</th>\n      <td>\":::::And for the second time of asking, when ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159567</th>\n      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159568</th>\n      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159569</th>\n      <td>And it looks like it was actually you who put ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159570</th>\n      <td>\"\\nAnd ... I really don't think you understand...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>159571 rows × 7 columns</p>\n</div>",
      "text/plain": "                                             comment_text  toxic  \\\n0       Explanation\\nWhy the edits made under my usern...      0   \n1       D'aww! He matches this background colour I'm s...      0   \n2       Hey man, I'm really not trying to edit war. It...      0   \n3       \"\\nMore\\nI can't make any real suggestions on ...      0   \n4       You, sir, are my hero. Any chance you remember...      0   \n...                                                   ...    ...   \n159566  \":::::And for the second time of asking, when ...      0   \n159567  You should be ashamed of yourself \\n\\nThat is ...      0   \n159568  Spitzer \\n\\nUmm, theres no actual article for ...      0   \n159569  And it looks like it was actually you who put ...      0   \n159570  \"\\nAnd ... I really don't think you understand...      0   \n\n        severe_toxic  obscene  threat  insult  identity_hate  \n0                  0        0       0       0              0  \n1                  0        0       0       0              0  \n2                  0        0       0       0              0  \n3                  0        0       0       0              0  \n4                  0        0       0       0              0  \n...              ...      ...     ...     ...            ...  \n159566             0        0       0       0              0  \n159567             0        0       0       0              0  \n159568             0        0       0       0              0  \n159569             0        0       0       0              0  \n159570             0        0       0       0              0  \n\n[159571 rows x 7 columns]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\r\n",
    "from no_toxicity.src.preprocessing.cleaning import Dfcleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the list of column to clean\r\n",
    "raw_comments=df['comment_text'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner=Dfcleaner()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 examples cleaned out of 159571\n",
      "20000 examples cleaned out of 159571\n",
      "30000 examples cleaned out of 159571\n",
      "40000 examples cleaned out of 159571\n",
      "50000 examples cleaned out of 159571\n",
      "60000 examples cleaned out of 159571\n",
      "70000 examples cleaned out of 159571\n",
      "80000 examples cleaned out of 159571\n",
      "90000 examples cleaned out of 159571\n",
      "100000 examples cleaned out of 159571\n",
      "110000 examples cleaned out of 159571\n",
      "120000 examples cleaned out of 159571\n",
      "130000 examples cleaned out of 159571\n",
      "140000 examples cleaned out of 159571\n",
      "150000 examples cleaned out of 159571\n",
      "Cleaning Done\n"
     ]
    }
   ],
   "source": [
    "cleaned_comments=cleaner.clean(raw_comments,stem=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 examples cleaned out of 159517\n",
      "20000 examples cleaned out of 159517\n",
      "30000 examples cleaned out of 159517\n",
      "40000 examples cleaned out of 159517\n",
      "50000 examples cleaned out of 159517\n",
      "60000 examples cleaned out of 159517\n",
      "70000 examples cleaned out of 159517\n",
      "80000 examples cleaned out of 159517\n",
      "90000 examples cleaned out of 159517\n",
      "100000 examples cleaned out of 159517\n",
      "110000 examples cleaned out of 159517\n",
      "120000 examples cleaned out of 159517\n",
      "130000 examples cleaned out of 159517\n",
      "140000 examples cleaned out of 159517\n",
      "150000 examples cleaned out of 159517\n",
      "Cleaning Done\n"
     ]
    }
   ],
   "source": [
    "cleaned_comments=cleaner.remove_frequent_rare(cleaned_comments,frequent=True,rare=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing with new data\r\n",
    "df['comment_text']=cleaned_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Saving the cleaned data\r\n",
    "# df.to_csv('../data/interim/cleaned_data1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\r\n",
    "df=pd.read_csv('../data/interim/cleaned_data1.csv')\r\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_col_value(row):\r\n",
    "    flag=True\r\n",
    "    # print(row.iloc[1:])\r\n",
    "    for i in row.iloc[1:]:\r\n",
    "        if i==1:\r\n",
    "            flag=False\r\n",
    "            break\r\n",
    "    if flag:\r\n",
    "        return 1\r\n",
    "    else:\r\n",
    "        return 0\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['not_toxic']=df.apply(lambda row:new_col_value(row),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "toxic             15294\nsevere_toxic       1595\nobscene            8449\nthreat              478\ninsult             7877\nidentity_hate      1405\nnot_toxic        143240\ndtype: int64"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,1:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=42)\r\n",
    "df,Y= rus.fit_resample(df.iloc[:,:-1],df.iloc[:,-1])\r\n",
    "df['not_toxic']=Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n      <th>not_toxic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cocksucker piss around work</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>hey exclusive group wp taliban good destroy se...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bye look come think comming back tosser</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>gay antisemmitian archangel white tiger meow g...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>fuck filthy mother as dry</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>32445</th>\n      <td>question think troll could explain nearly edit...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>32446</th>\n      <td>hello kyo sorry hear busy hope today find well...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>32447</th>\n      <td>zeer oude klanken en heel nieuwe geluiden surp...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>32448</th>\n      <td>response tord departure eddsworld follow death...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>32449</th>\n      <td>oh guy run nexgenwars year old somehow manage ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>32450 rows × 8 columns</p>\n</div>",
      "text/plain": "                                            comment_text  toxic  severe_toxic  \\\n0                            cocksucker piss around work      1             1   \n1      hey exclusive group wp taliban good destroy se...      1             0   \n2                bye look come think comming back tosser      1             0   \n3      gay antisemmitian archangel white tiger meow g...      1             0   \n4                              fuck filthy mother as dry      1             0   \n...                                                  ...    ...           ...   \n32445  question think troll could explain nearly edit...      0             0   \n32446  hello kyo sorry hear busy hope today find well...      0             0   \n32447  zeer oude klanken en heel nieuwe geluiden surp...      0             0   \n32448  response tord departure eddsworld follow death...      0             0   \n32449  oh guy run nexgenwars year old somehow manage ...      0             0   \n\n       obscene  threat  insult  identity_hate  not_toxic  \n0            1       0       1              0          0  \n1            0       0       0              0          0  \n2            0       0       0              0          0  \n3            1       0       1              1          0  \n4            1       0       1              0          0  \n...        ...     ...     ...            ...        ...  \n32445        0       0       0              0          1  \n32446        0       0       0              0          1  \n32447        0       0       0              0          1  \n32448        0       0       0              0          1  \n32449        0       0       0              0          1  \n\n[32450 rows x 8 columns]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\r\n",
    "from no_toxicity.src.preprocessing.preprocess import PrepareTheData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dummy\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\indexing.py:1843: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization Done\n",
      "Replacing Done\n",
      "token2idx created\n",
      "tokens_to_indices created\n",
      "Presprocessing done\n"
     ]
    }
   ],
   "source": [
    "dataset=PrepareTheData(df[['comment_text']],df.iloc[:,1:],max_vocab=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "2000"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.token2idx_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.999 * len(dataset))\r\n",
    "test_size = len(dataset) - train_size\r\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "([1417, 204, 472, 1782], array([1, 0, 1, 0, 0, 0, 0], dtype=int64))"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.dataset.__getitem__(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "def collate(batch):\r\n",
    "    inputs = [torch.LongTensor(item[0]) for item in batch]\r\n",
    "    targets = [item[1] for item in batch]\r\n",
    "    # print((inputs[0]))\r\n",
    "    targets=torch.Tensor(targets)\r\n",
    "    # print(targets[247])\r\n",
    "    # Pad sequencse so that they are all the same length (within one minibatch)\r\n",
    "    padded_inputs = pad_sequence(inputs, padding_value=dataset.token2idx_inputs[dataset.padding_token], batch_first=True)\r\n",
    "    # print(padded_inputs.shape)\r\n",
    " \r\n",
    "    # Sort by length for CUDA optimizations\r\n",
    "    lengths = torch.LongTensor([len(x) for x in inputs])\r\n",
    "    lengths, permutation = lengths.sort(dim=0, descending=True)\r\n",
    "    # print(permutation)\r\n",
    "    return padded_inputs[permutation].to(device), targets[permutation].to(device), lengths.to(device)\r\n",
    "\r\n",
    "\r\n",
    "batch_size = 256\r\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate,shuffle=True)\r\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, collate_fn=collate,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs,target,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\r\n",
    "from no_toxicity.src.models.encoder_decoder import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\r\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Github\\no_toxicity\\notebooks\n"
     ]
    }
   ],
   "source": [
    "model = LSTM(input_vocab_size=len(dataset.token2idx_inputs), \r\n",
    "            emd_dim=100, \r\n",
    "            hidden_size=256,\r\n",
    "            n_layers=1, \r\n",
    "            token_to_idx=dataset.token2idx_inputs)\r\n",
    "\r\n",
    "optimizer = optim.Adam([p for p in model.parameters() if p.requires_grad], lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\r\n",
    "model.train()\r\n",
    "for epoch in range(1):\r\n",
    "    total_loss = total = 0\r\n",
    "    progress_bar = tqdm.notebook.tqdm(train_loader, desc='Training', leave=False,total=len(train_loader))\r\n",
    "    for inputs, targets, lengths in progress_bar:\r\n",
    "        # Clean old gradients\r\n",
    "        optimizer.zero_grad()\r\n",
    "\r\n",
    "        # Forwards pass\r\n",
    "        loss,metric = model(inputs, targets, lengths)\r\n",
    "        # print(inputs[:,-1])\r\n",
    "        # Perform gradient descent, backwards pass\r\n",
    "        # break\r\n",
    "        loss.backward()\r\n",
    "\r\n",
    "        # Take a step in the right direction\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        # Record metrics\r\n",
    "        total_loss += loss\r\n",
    "        total += targets.size(1)\r\n",
    "\r\n",
    "    train_loss = total_loss / total\r\n",
    "    tqdm.notebook.tqdm.write(f'epoch #{epoch + 1:3d}\\ttrain_loss: {train_loss:.2e}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "name": "python388jvsc74a57bd07f3de5096ca57544369bb14db0d707c452af519be01e653fe2c6b8aa83f4de32"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "7f3de5096ca57544369bb14db0d707c452af519be01e653fe2c6b8aa83f4de32"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}